
# Hyper parameters for learning
optimizer_name: ADAM        # ADAM, SGD
learning_rate:  0.0001
weight_decay:   0.0009
max_epochs:     20
batch_size:     256
val_batch_size: 128
check_val_every_n_epoch: 5
log_every_n_steps: 10
es_patience: 3
label_weights: [ 1.4, 1.0]
# Accelerator
ngpus:           1.0
accelerator:    'gpu'

# Voxel default config
feature_set_key: ohm_sr
voxel_size: 0.1
nvoxel_leaf: 32
train_ratio: 0.8
shuffle: True
random_seed: 123456789


min_pose_dist: 1.0

# Model configuration
model_name:  UNet4LMCD
model_skip_connection_key: s3                                                                                                                                           
model_nfeature_enc_ch_out: 10
model_stride: [1, 2, 2, 2, 2, 2]
model_skip_connection: [0, 0, 0, 0, 0]
model_dropout: 0.05

# Data set parameters
training_strategy_key: simple_online_training
patch_bounds: [-1.6, -1.6, -1.0, 1.6, 1.6, 1.0]

# Data Augmentation
use_data_augmentation: True
data_augmenter_noise_chance: 0.00
data_augmenter_noise_mean: 0.0
data_augmenter_noise_std: 0.00
data_augmenter_sample_pruning_chance: 0.1
data_augmenter_batch_rotation_chance: 0.75
data_augmenter_batch_translation_chance: 0.5
data_augmenter_batch_nvoxel_displacement: 10.0
data_augmenter_mirror_chance: 0.5
