# Sparse Convolutional Neural Network for Forest Traversability Mapping (SCNN-FTM)
This work enables to train models for Traversability Estimation in vegetated environments. 


## QUICKSTART
The `train_model` will train a model and all the configurations are defined by the default_train.yaml.

This package `default_train.yaml` has all the default values and descriptions needed to train a model from scratch. 

The data set and trained models are stores on bowen, see the workspace [readme\[../\]](../../README.md). A newly trained model will contain the weights, scaler and a model_config_cv_#.yaml file. The models are aimed to be used in an ensemble. An ensemble runs N models in parallel, making the output more robust against outliers.

## Dependencies and installation
This package is intended to be built and used with a docker image. The installation/build instruction are provided in the `nve_docker` pkg, allowing to build images for jetson/orin architecture and amd86X architecture. 

The main dependencies are based on the learning
Cuda 11.7
TorchSparse v2.0.0b. (The newer version break ordering of coordinates and don't work)

## FAQ

### Inference of model is bad (but training is successful/yields good results):
Can occur when the alignment of the point cloud is violated. A voxel cloud can only contain one measurement per voxel. Check if there are any non-unique elements. This can commonly occur if the ohm cloud is transformed into a different (non-static) frame.


## Model overview:

There are two model configurations, the single classification head variant (LMCD) and the two head model (THM). For the single head model, there are the following options {Unet3LMCD,UNet4LMCD, UNet5LMCD} and for the two head model {UNet3THM, UNet4THM}. The two head model can either used the TwoHeadLoss, the TwoHeadProbLoss is for partially labelled data and should not be used for offline training. 

## DATA SET GENERATION
The data set used in this training loop are csv files where the following fields are expected. Tools such as CloudCompare can be used to hand-label ohm-clouds with the features and store the labeled data as as csv.

| Field Name | Description | Default values |
| - | -| - |
| x,y,z | voxel coordinates| - |
| label | voxel label {0,1} | Non-traversable (NTE) = 0, traversable (TR) = 1 |
|label_prob | Traversability likelihood [0,1] | For hand-labelled data NTE = 0., TR=0.7| 
| label_obs | If label was observed through self-supervision | For hand-labeled data label_obs=0, SSL label_obs=1 | 

The rest of the fields are named after the additional fields in the ohm mapping framework and some feature sets used in [1,2]. Currently, the most robust set of features is generated by the` feature set key`="occ_int_perm_mr". 


| Additional Field Names | Description | 
| - | -|
|occupancy_prob	| Occupancy probability [0,1] |
| occupancy_log_probability | Log odd formulation of probability	|
| occupancy | Occupancy label of voxel {0=occupied, 1=free}|
| intensity_mean | Intensity value 0-255 (normal values should be 0-125) |	
| intensity_covariance | Covariance of intensity measurements |
| miss_count | Permeability hit count (NDT-TM) |	
| hit_count | Permeability hit count (NDT-TM) |	
| permeability | Permeability, chance of a ray passing through a voxel even though it contains measurements |	
| covariance_xx_sqrt | Covariance entry (NDT-OM) |	
| covariance_xy_sqrt | Covariance entry (NDT-OM) |	
| covariance_yy_sqrt | Covariance entry (NDT-OM) |	
| covariance_xz_sqrt | Covariance entry (NDT-OM) |	
| covariance_yz_sqrt | Covariance entry (NDT-OM) |	
| covariance_zz_sqrt | Covariance entry (NDT-OM) |	
| traversal | Raw value for decay rate, see decay rate measure (not commonly used) |	
| secondary_sample_count | Number of secondary sample count per voxels |	
| secondary_sample_range_mean | Mean distance ( primary endpoint and SR endpoint ) for which the primary ray ends in this voxel (not commonly used)|	
| secondary_sample_range_std_dev | Standard deviation (not commonly used) |	
| red | Red colour field in 0-255 (not commonly used) |	
| green | Green colour field 0-255 (not commonly used) |	
| blue | Blue colour field 0-255 (not commonly used ) |	
| colour_count | Count of total number of colourised measurements |	
| ndt_rho | Magnitude of the first eigenvalue, considered a measure for roughness (NDT-TM) |	
| theta | Angle (rad) between the gravity aligned normal and the plane of the two smaller eigenvalues |	
| ev_lin | Linear eigenvalue feature |	
| ev_plan | Planar eigenvalue feature |	
| ev_sph | Spherical eigenvalue feature |

Notes:
- Intensity values can change or differ between sensor model of the same sensors (e.x. VLP-16) or between different lidar models. The ones in the training set may not be suitable for all examples.

- The eigen-value feature (ndt_rho, theta, ev_lin, ev_plan, ev_sph) are dependent on number of endpoint observations per voxel. The eigen-value decomposition is computationally expensive and can be malformed if there is not many(20-100+) measurements. Same reason to used the covariance features with caution. 

- Colour fusion in forest can lead to decrease in performance, if the colour is not clear within a voxel or if the training data set has frequent occlusions and painting the voxels the wrong colour. 

- In some of the older (online) data sets there are `mean_<feature_name>` features. This is a mean value convolution for a voxel given its 27 neighbours. This contextual averaging doubles the feature set size (good for classical methods) but not necessary when using 3D convolutions. 

