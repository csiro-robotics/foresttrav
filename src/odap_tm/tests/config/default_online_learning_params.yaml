# Experiment configurations
experiment_name:  '24_2_15_sim_moldels'
experiment_root_dir: /data/experiments/debug_online_ft/2024_05_09
debug: True       # Flag to enter into debug mode, will not use wandb
evaluate_test_set: True
metric_rounding: 4
save_model: True


# Contioual learning parameters
ft_lr: 0.00001     # The fintune learning rate
base_lr:  0.0001     # The initial learning rate
online_data_root_dir: /data/temp/qcat_forest_1_lmix
use_unlabeled_data: False
cont_learning: False
use_pretrained_model: False
base_model_config: /data/base_models_hl_2024_05_01/sparse_base/24_05_03_22_09_UNet4THM_occ_int_hm_mr_test_train/model_config_cv_2.yaml

use_default_scaler: False
default_scaler_path: ""

training_strategy_key: None # est_train, cv_test_train,  cv_patch, cv_scene
use_data_set_key: False
data_set_key:  None         # lfe_hl: hand-labelled, lfe_cl: confident hand-labels 
base_train_data_sets: []

base_test_data_sets: 
  - "/data/forest_trav/lfe_hl_v0.1/9_2022_02_14_23_47_33Z.csv" 

patch_strategy: grid
patch_width: 3.2
min_pose_dist: 0.3

train_ratio: 0.8
min_patch_sample_nbr: 100
use_cv: False
max_cv: 1
cv_nbr: 0

# Hyper parameters for learning
lr:  0.0001
weight_decay:   0.0009
max_epochs:     40
batch_size:     64
val_batch_size: 64
check_val_every_n_epoch: 3
es_patience: 2
use_label_weights: False
ce_label_weights: [ 1.0,  0.5]
ce_threshold: [0.2, 0.8]      # Threshold use to get the model 
# Accelerator
ngpus:           1.0
accelerator:    'cuda'

# Voxel default config
feature_set_key: occ
voxel_size: 0.1
nvoxel_leaf: 32
shuffle: True
random_seed: 23111989

# Loss configureation
loss_function_tag: TwoHeadLoss 
ce_loss_weight: 2.0
rec_loss_weight: 0.25

# Model configuration
model_name:  UNet4LMCD #UNet4LMCD, UNet4THM
model_skip_connection_key: s3
model_stride: [1, 2, 2, 2, 2, 2]
model_skip_connection: [0, 0, 0, 0, 0]
model_nfeature_enc_ch_out: 12

# Data Augmentation
use_data_augmentation: True
data_augmenter_noise_chance: 0.0
data_augmenter_noise_mean: 0.0
data_augmenter_noise_std: 0.00
data_augmenter_sample_pruning_chance: 0.05
data_augmenter_batch_rotation_chance: 0.5
data_augmenter_batch_translation_chance: 0.25
data_augmenter_batch_nvoxel_displacement: 5.0
data_augmenter_mirror_chance: 0.25

# Feature scaling
use_feature_scaling: True
